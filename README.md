[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/Vipermdl/AI-Ocean-Models-LiuGroup/graphs/commit-activity)
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/Vipermdl/AI-Ocean-Models-LiuGroup)
<img alt="GitHub watchers" src="https://img.shields.io/github/watchers/Vipermdl/AI-Ocean-Models-LiuGroup?style=social"> <img alt="GitHub stars" src="https://img.shields.io/github/stars/Vipermdl/AI-Ocean-Models-LiuGroup?style=social"> <img alt="GitHub forks" src="https://img.shields.io/github/forks/Vipermdl/AI-Ocean-Models-LiuGroup?style=social">

# <p align=center>`Awesome AI Ocean Models`</p>

:star2:**A collection of papers, datasets, benchmarks, code for AI Ocean Models in ECNU.**

## üì¢ Latest Updates
:fire::fire::fire: Last Updated on 2025.05.12 :fire::fire::fire:

## Table of Contents
- **Models**
  - [AI Ocean Models](#remote-sensing-vision-foundation-models)
- **Datasets & Benchmarks**
  - [Benchmarks for Ocean](#benchmarks-for-rSFMs)
- **Others**
  - [Relevant Projects](#relevant-projects)
  - [Survey Papers](#survey-papers)
  
## AI <ins>Ocean</ins> Models

|Abbreviation|Title|Publication|Paper|Code & Weights|
|:---:|---|:---:|:---:|:---:|
|**GeoKR**|**Geographical Knowledge-Driven Representation Learning for Remote Sensing Images**|TGRS2021|[GeoKR](https://ieeexplore.ieee.org/abstract/document/9559903)|[link](https://github.com/flyakon/Geographical-Knowledge-driven-Representaion-Learning)|
|**-**|**Self-Supervised Learning of Remote Sensing Scene Representations Using Contrastive Multiview Coding**|CVPRW2021|[Paper](https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Stojnic_Self-Supervised_Learning_of_Remote_Sensing_Scene_Representations_Using_Contrastive_Multiview_CVPRW_2021_paper.html)|[link](https://github.com/vladan-stojnic/CMC-RSSR)|
|**GASSL**|**Geography-Aware Self-Supervised Learning**|ICCV2021|[GASSL](https://openaccess.thecvf.com/content/ICCV2021/html/Ayush_Geography-Aware_Self-Supervised_Learning_ICCV_2021_paper.html)|[link](https://github.com/sustainlab-group/geography-aware-ssl)|
|**SeCo**|**Seasonal Contrast: Unsupervised Pre-Training From Uncurated Remote Sensing Data**|ICCV2021|[SeCo](https://openaccess.thecvf.com/content/ICCV2021/html/Manas_Seasonal_Contrast_Unsupervised_Pre-Training_From_Uncurated_Remote_Sensing_Data_ICCV_2021_paper.html)|[link](https://github.com/ServiceNow/seasonal-contrast)|
|**DINO-MM**|**Self-supervised Vision Transformers for Joint SAR-optical Representation Learning**|IGARSS2022|[DINO-MM](https://arxiv.org/abs/2204.05381)|[link](https://github.com/zhu-xlab/DINO-MM)|
|**SatMAE**|**SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery**|NeurIPS2022|[SatMAE](https://proceedings.neurips.cc/paper_files/paper/2022/hash/01c561df365429f33fcd7a7faa44c985-Abstract-Conference.html)|[link](https://github.com/sustainlab-group/SatMAE)|

## Benckmark For Ocean

|Abbreviation|Title|Publication|Paper|Code & Weights|
|:---:|---|:---:|:---:|:---:|
|**RSGPT**|**RSGPT: A Remote Sensing Vision Language Model and Benchmark**|Arxiv2023|[RSGPT](https://arxiv.org/abs/2307.15266)|[link](https://github.com/Lavender105/RSGPT)|
|**RemoteCLIP**|**RemoteCLIP: A Vision Language Foundation Model for Remote Sensing**|Arxiv2023|[RemoteCLIP](https://arxiv.org/abs/2306.11029)|[link](https://github.com/ChenDelong1999/RemoteCLIP)|

# Relevant Projects
*ÔºàTODO. This section is dedicated to recommending more relevant and impactful projects, with the hope of promoting the development of the RS community. :smile: :rocket:Ôºâ*
|Title|Link|Brief Introduction|
|---|:---:|:---:|
|**RSFMs (Remote Sensing Foundation Models) Playground**|[link](https://github.com/synativ/RSFMs)|An open-source playground to streamline the evaluation and fine-tuning of RSFMs on various datasets.|
|**PANGAEA**|[link](https://github.com/yurujaja/pangaea-bench)|A Global and Inclusive Benchmark for Geospatial Foundation Models.|
|**GeoFM**|[link](https://github.com/xiong-zhitong/GeoFM)|Evaluation of Foundation Models for Earth Observation.|
|**EOUncertaintyGeneralization**|[link](https://github.com/Orion-AI-Lab/EOUncertaintyGeneralization)|On the Generalization of Representation Uncertainty in Earth Observation.|

## Survey/Commentary Papers
|Title|Publication|Paper|Attribute|
|---|:---:|:---:|:---:|
|**Self-Supervised Remote Sensing Feature Learning: Learning Paradigms, Challenges, and Future Works**|TGRS2023|[Paper](https://ieeexplore.ieee.org/abstract/document/10126079)|**Vision & Vision-Language**|
|**The Potential of Visual ChatGPT For Remote Sensing**|Arxiv2023|[Paper](https://arxiv.org/abs/2304.13009)|**Vision-Language**|
|**ÈÅ•ÊÑüÂ§ßÊ®°ÂûãÔºöËøõÂ±ï‰∏éÂâçÁûª**|Ê≠¶Ê±âÂ§ßÂ≠¶Â≠¶Êä• (‰ø°ÊÅØÁßëÂ≠¶Áâà) 2023|[Paper](http://ch.whu.edu.cn/cn/article/doi/10.13203/j.whugis20230341?viewType=HTML)|**Vision & Vision-Language**|
|**Âú∞ÁêÜ‰∫∫Â∑•Êô∫ËÉΩÊ†∑Êú¨ÔºöÊ®°Âûã„ÄÅË¥®Èáè‰∏éÊúçÂä°**|Ê≠¶Ê±âÂ§ßÂ≠¶Â≠¶Êä• (‰ø°ÊÅØÁßëÂ≠¶Áâà) 2023|[Paper](http://ch.whu.edu.cn/article/id/5e67ed6a-aae5-4ec0-ad1b-f2aba89f4617)|**-**|
|**Brain-Inspired Remote Sensing Foundation Models and Open Problems: A Comprehensive Survey**|JSTARS2023|[Paper](https://ieeexplore.ieee.org/abstract/document/10254282)|**Vision & Vision-Language**|
|**Revisiting pre-trained remote sensing model benchmarks: resizing and normalization matters**|Arxiv2023|[Paper](https://arxiv.org/abs/2305.13456)|**Vision**|
|**An Agenda for Multimodal Foundation Models for Earth Observation**|IGARSS2023|[Paper](https://ieeexplore.ieee.org/abstract/document/10282966)|**Vision**|
|**Transfer learning in environmental remote sensing**|RSE2024|[Paper](https://www.sciencedirect.com/science/article/pii/S0034425723004765)|**Transfer learning**|
|**ÈÅ•ÊÑüÂü∫Á°ÄÊ®°ÂûãÂèëÂ±ïÁªºËø∞‰∏éÊú™Êù•ËÆæÊÉ≥**|ÈÅ•ÊÑüÂ≠¶Êä•2023|[Paper](https://www.ygxb.ac.cn/zh/article/doi/10.11834/jrs.20233313/)|**-**|
|**On the Promises and Challenges of Multimodal Foundation Models for Geographical, Environmental, Agricultural, and Urban Planning Applications**|Arxiv2023|[Paper](https://arxiv.org/abs/2312.17016)|**Vision-Language**|
|**Vision-Language Models in Remote Sensing: Current Progress and Future Trends**|IEEE GRSM2024|[Paper](https://arxiv.org/abs/2305.05726)|**Vision-Language**|
|**On the Foundations of Earth and Climate Foundation Models**|Arxiv2024|[Paper](https://arxiv.org/abs/2405.04285)|**Vision & Vision-Language**|
|**Towards Vision-Language Geo-Foundation Model: A Survey**|Arxiv2024|[Paper](https://arxiv.org/abs/2406.09385)|**Vision-Language**|
|**AI Foundation Models in Remote Sensing: A Survey**|Arxiv2024|[Paper](https://arxiv.org/abs/2408.03464)|**Vision**|
|**Foundation model for generalist remote sensing intelligence: Potentials and prospects**|Science Bulletin2024|[Paper](https://www.sciencedirect.com/science/article/pii/S2095927324006510?via%3Dihub)|**-**|
|**Advancements in Visual Language Models for Remote Sensing: Datasets, Capabilities, and Enhancement Techniques**|Arxiv2024|[Paper](https://arxiv.org/abs/2410.17283)|**Vision-Language**|
|**Foundation Models for Remote Sensing and Earth Observation: A Survey**|Arxiv2024|[Paper](https://arxiv.org/abs/2410.16602)|**Vision & Vision-Language**|
|**Â§öÊ®°ÊÄÅÈÅ•ÊÑüÂü∫Á°ÄÂ§ßÊ®°ÂûãÔºöÁ†îÁ©∂Áé∞Áä∂‰∏éÊú™Êù•Â±ïÊúõ**|ÊµãÁªòÂ≠¶Êä•2024|[Paper](http://xb.chinasmp.com/CN/10.11947/j.AGCS.2024.20240019.)|**Vision & Vision-Language & Generative & Vision-Location**|
|**When Geoscience Meets Foundation Models: Toward a general geoscience artificial intelligence system**|IEEE GRSM2024|[Paper](https://ieeexplore.ieee.org/abstract/document/10770814)|**Vision & Vision-Language**|
|**Towards the next generation of Geospatial Artificial Intelligence**|JAG2025|[Paper](https://www.sciencedirect.com/science/article/pii/S1569843225000159)|**-**|
|**Vision Foundation Models in Remote Sensing: A survey**|IEEE GRSM2025|[Paper](https://ieeexplore.ieee.org/abstract/document/10916803)|**Vision**|
|**Unleashing the potential of remote sensing foundation models via bridging data and computility islands**|The Innovation2025|[Paper](https://www.cell.com/the-innovation/fulltext/S2666-6758(25)00044-X)|**-**|
|**A Survey on Remote Sensing Foundation Models: From Vision to Multimodality**|Arxiv2025|[Paper](https://arxiv.org/abs/2503.22081)|**-**|


## Citation

If you find this repository useful, please consider giving a star :star: and citation:

```
@inproceedings{guo2024skysense,
  title={Skysense: A multi-modal remote sensing foundation model towards universal interpretation for earth observation imagery},
  author={Guo, Xin and Lao, Jiangwei and Dang, Bo and Zhang, Yingying and Yu, Lei and Ru, Lixiang and Zhong, Liheng and Huang, Ziyuan and Wu, Kang and Hu, Dingxiang and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27672--27683},
  year={2024}
}

@article{li2025unleashing,
  title={Unleashing the potential of remote sensing foundation models via bridging data and computility islands},
  author={Li, Yansheng and Tan, Jieyi and Dang, Bo and Ye, Mang and Bartalev, Sergey A and Shinkarenko, Stanislav and Wang, Linlin and Zhang, Yingying and Ru, Lixiang and Guo, Xin and others},
  journal={The Innovation},
  year={2025},
  publisher={Elsevier}
}
```
